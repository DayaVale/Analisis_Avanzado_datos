{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica: clasificación con Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta primera parte se trabaja con el dataset `smarket.csv`, cuya descripción (en el libro ISLR) es la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "**Los datos del mercado de valores**\n",
    "\n",
    "Comenzaremos examinando algunos resúmenes numéricos y gráficos de los datos de Smarket. Este conjunto de datos consta de rendimientos porcentuales para el índice bursátil S&P 500 durante 1250 días, desde principios de 2001 hasta finales de 2005. Para cada fecha, hemos registrado los rendimientos porcentuales para cada uno de los cinco días de negociación anteriores, Lag1 a Lag5. También hemos registrado `Volume` (el número de acciones negociadas el día anterior, en miles de millones), `Today` (el porcentaje de rendimiento en la fecha en cuestión) y `Direction` (si el mercado estaba al alza o a la baja en esta fecha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaremos la mayoria de modulos que se utilizaran a lo largo de la práctica\n",
    "\n",
    "# Modulos basicos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Modulos de scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, accuracy_score \n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Statmodels\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando el dataset de stock market "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smarket = pd.read_csv('smarket.csv')\n",
    "smarket.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(8,7))\n",
    "sns.heatmap(smarket.corr(),cmap = 'ocean_r', annot=True, cbar=False )\n",
    "ax.set_title('Correlation matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aprecia una gran correlación entre `Year` y `Volume`. De hecho, al graficar `Volume` se puede ver una tendencia a incrementarse con el tiempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor graficar con programacion orientada a objetos (POO)\n",
    "# como arriba [estoy muy acostumbrado a Matlab ;) ]\n",
    "plt.plot(smarket['Volume'])\n",
    "plt.title('Volume')\n",
    "plt.xlabel('Time (days)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizará un modelo de regresión logística para predecir `Direction` usando `Lag1`, ..., `Lag5`, y `Volume`.\n",
    "\n",
    "### Usando `statmodels` (análisis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codifica la variable de salida categorica \"Direction\": # Up -> 1, Down -> 0.\n",
    "# Esto se hace para statmodels, con scikit-learn no es necesario\n",
    "# codificar la variable de salidad, pero si los predictores categoricos.\n",
    "smarket['Up'] =  np.where(smarket['Direction'] == 'Up', 1, 0)\n",
    "\n",
    "lrmodel = smf.logit('Up ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume', data=smarket)\n",
    "results = lrmodel.fit()\n",
    "results.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor-p menor esta asociado con `Lag1`. El coeficiente negativo para este predictor sugiere que si el mercado tuvo un retorno positivo ayer, entonces es menos probable que suba hoy. Sin embargo, un valor-p de 0.15 es aún relativamente grande, por lo que no hay una clara evidencia de que exista una asociación real entre `Lag1` y `Direction`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora con scikit-learn (predicción)\n",
    "Para realizar una predicción se tomará los años anteriores a 2005 como training y el 2005 para test. Es decir, se hará la predicción del año 2005 basado en los años anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = smarket.loc[:,'Lag1':'Volume']\n",
    "y = smarket['Up']\n",
    "\n",
    "# Dividiendo en training y test\n",
    "idx_train = smarket['Year'].values < 2005\n",
    "X_train = X[idx_train]\n",
    "X_test = X[~idx_train]\n",
    "y_train = y[idx_train]\n",
    "y_test = y[~idx_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmodel = LogisticRegression(solver='lbfgs')\n",
    "lrmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusion sobre el test\n",
    "y_pred = lrmodel.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['Down','Up'], columns=['Down','Up'])\n",
    "cm_df.index.name = 'True'; cm_df.columns.name = 'Predicted'\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para no llamar cada vez el código de la matriz de confusión, he creado una función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para calcular la matriz de confusion \n",
    "def miCM(ytrue, ypred, clases=None, normalize = False):\n",
    "    \"\"\" Funcion para calcular la matriz de confusion en forma de dataframe\"\"\"\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    CM = confusion_matrix(ytrue,ypred)\n",
    "    \n",
    "    #Normaliza la matriz de confusion dividiendo cada fila por el total de verdaderos\n",
    "    if normalize:\n",
    "        CM = 100*CM / CM.sum(axis=1).reshape(-1,1) #Aprovechando el Broadcasting!\n",
    "    if clases == None:\n",
    "        clases = list(set(ytrue))    \n",
    "    df = pd.DataFrame(CM, index=clases, columns=clases)\n",
    "    df.index.name = 'True'; df.columns.name = 'Predicted'\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miCM(y_test,y_pred, ['Down','Up'], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento\n",
    "\n",
    "En muchas ocasiones es importante **preprocesar** los predictores. Por ejemplo, realizando una estandarización (restar la media y dividir por la desviación estándar). En scikit-learn se puede llamar mediante `sklearn.preprocessing.StandardScaler()`. En la documentación de [preprocessing](http://scikit-learn.org/stable/modules/preprocessing.h) se encuentran otros tipos de preprocesamiento y más información al respecto. A continuación se verá que sucede al escalar los predictores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se instancia al objeto StandarScaler para realizar el ajuste\n",
    "# Esto es muy adecuado para preprocesar de la misma forma al test\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# Regresion logistica como antes pero escalando los predictores\n",
    "lrmodel = LogisticRegression(solver='lbfgs')\n",
    "lrmodel.fit( scaler.transform(X_train),y_train )\n",
    "\n",
    "# Prediccion pero escalando los predictores\n",
    "y_pred = lrmodel.predict( scaler.transform(X_test) )\n",
    "\n",
    "# matriz de confusion sin normalizacion\n",
    "miCM(y_test,y_pred, ['Down','Up'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "El error del test se puede calcular como $1 - accuracy$. Para el que desee saber más acerca de como imprimir valores en python puede ir a [este excelente tutorial](https://pyformat.info/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test error\n",
    "print(\"El accuracy del test es: {:.2f}\".format( accuracy_score(y_test,y_pred) ))\n",
    "test_error = 1-accuracy_score(y_test,y_pred)\n",
    "print(\"El error del test es: {:.2f}\".format( test_error ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué sucede si se realiza el ajuste considerando sólo los predictores con valor-p más alto, es decir, `Lag1` y `Lag2`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomando de nuevo los datos\n",
    "X = smarket[['Lag1','Lag2']]\n",
    "y = smarket['Direction'] # No es necesario para sklearn codificar la variable de salida\n",
    "\n",
    "# Dividiendo en training y test\n",
    "idx_train = smarket['Year'].values < 2005\n",
    "X_train = X[idx_train]\n",
    "X_test = X[~idx_train]\n",
    "y_train = y[idx_train]\n",
    "y_test = y[~idx_train]\n",
    "\n",
    "# Creacion del modelo y prediccion con preprocesamiento\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "lrmodel = LogisticRegression(solver='lbfgs')\n",
    "lrmodel.fit( scaler.transform(X_train),y_train )\n",
    "y_pred = lrmodel.predict( scaler.transform(X_test) )\n",
    "\n",
    "# matriz de confusion sin normalizacion\n",
    "miCM(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se nota una mejora, que se puede verificar con el accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"El accuracy del test es: {:.2f}\".format( accuracy_score(y_test,y_pred) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Esta pregunta debe responderse utilizando el dataset ``Weekly``. Esta información es similar a los datos de ``Smarket`` del anterior notebook, excepto que contiene 1,089 declaraciones semanales durante 21 años, desde el comienzo de 1990 hasta el final de 2010.\n",
    "\n",
    "(a) Produzca algún resumen numérico y algunos gráficos de ``Weekly``. ¿Hay algún patrón?\n",
    "\n",
    "(b) Utilice el conjunto de datos completo para realizar una regresión logística con ``Direction`` como respuesta y las cinco variables ``lag`` más ``Volume`` como predictores. Use la función ``summary`` (de statmodels) para imprimir los resultados. ¿Alguno de los predictores parece ser estadísticamente significativo? ¿De ser asi, cuales?\n",
    "\n",
    "(c) Calcule la matriz de confusión y la fracción general de las predicciones correctas. Explique qué le está diciendo la matriz de confusión sobre los tipos de errores cometidos por la regresión logística.\n",
    "\n",
    "(d) Ahora ajuste el modelo de regresión logística utilizando un período de datos de capacitación de 1990 a 2008, con ``Lag2`` como el único predictor. Calcule la matriz de confusión y la fracción general de las predicciones correctas para los datos retenidos (es decir, los datos de 2009 y 2010).\n",
    "\n",
    "(e) Repetir (d) usando KNN con K = 1.\n",
    "\n",
    "(h) ¿Cuál de estos métodos parece proporcionar los mejores resultados en estos datos?\n",
    "\n",
    "(i) Experimentar con diferentes combinaciones de predictores, incluidas posibles transformaciones e interacciones, para cada uno de los métodos. Realice un informe sobre las variables, el método y la matriz de confusión correspondiente, que parecen proporcionar los mejores resultados. Tenga en cuenta que también debe experimentar con valores para K en el clasificador KNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
