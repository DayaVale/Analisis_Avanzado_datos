{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac3523d",
   "metadata": {},
   "source": [
    "# Valores perdidos e Imputación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a2f243",
   "metadata": {},
   "source": [
    "Los valores perdidos son unos de los problemas más comunes que hay en el análisis de datos real, puesto que casi todos los datasets reales presentan valores que se ignoran, o no se anotan, o se comenten errores y se llenan mal, entre otras formas de no obtener la información. \n",
    "\n",
    "Al ser un problema muy frecuente, es de gran importancia en el manejo de los datos. A continuación veremos en primer lugar las clases de valores perdidos que se pueden presentar y por otro lado algunas técnicas que sirven para tratar éste problema. Nos centraremos especialmente en una técnica denominada **imputación**, que consiste en reconstruir los valores perdidos observando el resto del dataset (observando sólo una variable o múltiples variables). \n",
    "\n",
    "Es muy importante aclarar que no existe la forma perfecta de manejar el problema de los valores perdidos, hay muchos tipos de soluciones y dependerá de la estructura de los datos y el tipo de problema, en encontrar una solución adecuada. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f676c7",
   "metadata": {},
   "source": [
    "## Suposiciones de (por qué) los valores (están) perdidos\n",
    "\n",
    "Como en muchos tipos de modelos realizar ciertas suposiciones simplifica el manejo que se le puede dar a los datos y así a la construcción de métodos que nos ayudan a solucionar el problema.\n",
    "\n",
    "En el caso de los valores perdidos veremos tres suposiciones de por qué los valores están perdidos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a11c42",
   "metadata": {},
   "source": [
    "### Missing Completely at Random (MCAR) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2916e15f",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "*Missing Completely at Random* (MCAR), traducido sería algo como \"perdido completamente de forma aleatoria\",  supone que el hecho de que falte un determinado valor no tiene nada que ver con su valor hipotético ni tampoco con los valores de otras variables. De una forma más estadística, sería plantear que $\\color{green}{M_{Y} \\perp Y, X}$, siendo $M_Y$ una variable indicadora que indica cuando un valor es perdido (1 cuando es perdido, o 0 cuando es observado). Más formalmente, lo anterior es equivalente a: \n",
    "\n",
    "$$\n",
    "\\operatorname{Pr}(Y=y, X=x)=\\operatorname{Pr}\\left(Y=y, X=x \\mid M_{Y}=0\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd5234",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Entonces, cualquier cosa que podamos identificar a partir de los datos completos (porque es una función de la distribución conjunta) es también algo que podemos identificar a partir de la distribución con los datos incompletos (después de eliminarlos).\n",
    "\n",
    "MCAR es la suposición más fuerte y la menos creíble en situaciones reales. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dad3391",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "#### Ejemplo MCAR:\n",
    "Se imprimió una tabla de datos sin valores perdidos y alguien accidentalmente dejó caer un poco de tinta sobre ella, por lo que algunas celdas ya no se pueden leer. Aquí, podríamos suponer que los valores perdidos siguen la misma distribución que los valores conocidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de61f898",
   "metadata": {},
   "source": [
    "### Missing at Random (MAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c298b35",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "*Missing at Random* (MAR) significa que la probabilidad de perderse un dato no está relacionada con los datos perdidos, sino con algunos de los datos observados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acf80ca",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Debido a que MCAR es una suposición tan fuerte e inverosímil, se ha buscado suposiciones más débiles. MAR supone que:\n",
    "$$\n",
    "M_{Y} \\perp Y \\mid X\n",
    "$$\n",
    "Según la definición de independencia condicional, esto equivale a decir que, para todos los $x, y$\n",
    "$$\n",
    "\\operatorname{Pr}\\left(Y=y \\mid X=x, M_{Y}=0\\right)=\\operatorname{Pr}\\left(Y=y \\mid X=x, M_{Y}=1\\right)\n",
    "$$\n",
    "En otras palabras: dado $X$, los valores perdidos de $Y$ siguen exactamente la misma distribución de probabilidad que los valores observados. O lo mismo que:\n",
    "$$\n",
    "\\operatorname{Pr}(Y=y \\mid X=x)=\\operatorname{Pr}\\left(Y=y \\mid X=x, M_{Y}=0\\right)\n",
    "$$\n",
    "Por lo tanto, bajo MAR, cualquier función de la distribución condicional de datos completos se puede calcular directamente a partir de la distribución condicional observada. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b44b81",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "#### Ejemplos MAR:\n",
    "- En el caso de un sensor de temperatura, el hecho de que falte un valor no depende de la temperatura, pero puede depender de algún otro factor, por ejemplo, de la carga de la batería del termómetro.\n",
    "\n",
    "- Si alguien responde o no a una pregunta en una encuesta, por ejemplo, ¿cuál es su edad? no depende de la respuesta en sí, sino que puede depender de la respuesta a otra pregunta, por ejemplo, el sexo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae003d5",
   "metadata": {},
   "source": [
    "### Missing Not At Random (MNAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62200c",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Lo opuesto a *missing-at-random* es, naturalmente, *missing-not-at-random*, o MNAR:\n",
    "\n",
    "$$\n",
    "M_{Y} \\not \\perp Y \\mid X\n",
    "$$\n",
    "\n",
    "En otras palabras, la probabilidad de que un valor esté perdido puede depender del valor de la misma variable.\n",
    "\n",
    "MNAR también recibe los nombres de *non-ignorable-missingness* o *informative-missingness* (algo así como: \"los valores perdidos son informativos\")\n",
    "\n",
    "Cuando los valores perdidos son informativos, los argumentos de antes, usados en MAR nos dicen que la eliminación de los valores perdidos es una mala idea. Específicamente,\n",
    "\n",
    "$$\n",
    "\\operatorname{Pr}(Y=y \\mid X=x) \\neq \\operatorname{Pr}\\left(Y=y \\mid X=x, M_{Y}=0\\right)\n",
    "$$\n",
    "\n",
    "Es decir que, los datos observados no siguen la misma distribución condicional que los datos completos, y la eliminación de los valores perdidos nos dará una idea sesgada y sistemáticamente distorsionada de esa distribución condicional.\n",
    "\n",
    "Hay muy poco más que se pueda decir a este nivel de generalidad en el MNAR. En particular, si bien la ausencia es informativa, puede o no, ser muy informativa. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff02a9ca",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "#### Ejemplo MNAR\n",
    "- En el caso de un sensor de temperatura, el sensor no funciona correctamente cuando hace menos de 5°C.\n",
    "- Si alguien responde o no a una pregunta en una encuesta, por ejemplo, el número de días de enfermedad - depende de la respuesta en sí misma - como podría ser para algunas personas con sobrepeso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca29ac2",
   "metadata": {},
   "source": [
    "## Métodos para tratar con los valores perdidos (además de eliminarlos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3439bfa1",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Se pueden utilizar algunos métodos para tratar los datos perdidos, ya sea que asumamos MAR o MNAR (aunque darán respuestas diferentes en los dos casos). Los más importantes son:\n",
    "\n",
    "- Reconstruir o imputar valores para las variables con valores perdidos y analizar el conjunto de datos completo;\n",
    "\n",
    "- Promediar el logaritmo de la función de verosimilitud sobre todos los valores posibles de las variables con valores perdidos, utilizando el algoritmo EM;\n",
    "\n",
    "- Ponderación de las observaciones completas, de modo que el punto que consideremos apropiado represente los valores que se perdieron.\n",
    "\n",
    "Nos centraremos particularmente en la **imputación**. Si desean conocer con más profundidad los otros métodos les recomiendo el ápendice $\\text{I}$ de [éste libro](http://www.stat.cmu.edu/~cshalizi/ADAfaEPoV/) (del cual he tomado varias cosas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00488c42",
   "metadata": {},
   "source": [
    "La siguiente figura, tomada [de aquí](https://towardsdatascience.com/how-to-handle-missing-data-8646b18db0d4) muestra algunos métodos para borrar elementos o realizar imputación. \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/875/1*_RA3mCS30Pr0vUxbp25Yxw.png\" width=\"500\">\n",
    "\n",
    "Nota: por ahora, no veremos (en detalle) los métodos para tratar con valores perdidos en las series temporales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f691563",
   "metadata": {},
   "source": [
    "Siguiendo con la clasificación de los métodos, presentada anteriormente, a continuación se describen los métodos de eliminación y de imputación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0d267",
   "metadata": {},
   "source": [
    "### Métodos de eliminación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bc8b15",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Hay tres enfoques de eliminación comunes: eliminación por lista, eliminación por pares y características de eliminación.\n",
    "\n",
    "- *Listwise Deletion*: elimine todas las filas en las que falten uno o más valores.\n",
    "- *Pairwise Deletion*: elimine solo las filas que tienen valores perdidos en las columnas utilizadas para el análisis. Solo se recomienda utilizar este método si los datos que faltan son MCAR.\n",
    "- *Dropping Features*: elimine columnas enteras con más valores perdidos que un umbral determinado, por ejemplo, 60%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741955cb",
   "metadata": {},
   "source": [
    "La siguiente figura muestra un esquema de ejemplo para cada uno de los enfoques de eliminación.\n",
    "\n",
    "<img src=\"img/missing-values.jpg\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10673a",
   "metadata": {},
   "source": [
    "### Métodos de Imputación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f55b2d6",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "La idea detrás del método de imputación es reemplazar los valores perdidos con otros valores. Debido a que siempre se pierde información cuando se descartan muestras (filas) o entidades completas (columnas), la imputación suele ser un método muy valorado.\n",
    "\n",
    "Las numerosas técnicas de imputación se pueden dividir en dos subgrupos: imputación única e imputación múltiple.\n",
    "\n",
    "En la **imputación única** (*single imputation*), se genera un valor de imputación único / uno para cada una de las observaciones perdidas. El valor imputado se trata como el valor real, ignorando el hecho de que ningún método de imputación puede proporcionar el valor exacto. Por lo tanto, la imputación única no refleja la incertidumbre de los valores perdidos.\n",
    "\n",
    "En la **imputación múltiple** (*multiple imputation*), se generan muchos valores imputados para cada una de las observaciones perdidas. Esto significa que se crean muchos conjuntos de datos completos con diferentes valores imputados. El análisis (por ejemplo, entrenar una regresión lineal para predecir una columna de destino) se realiza en cada uno de estos conjuntos de datos y se infieren los resultados (por ejemplo, a través del promedio). La creación de imputaciones múltiples, a diferencia de las imputaciones únicas, explica la incertidumbre estadística en las imputaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d9b37",
   "metadata": {},
   "source": [
    "#### Imputación Única"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772aa690",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "La mayoría de los métodos de imputación son métodos de imputación única, siguiendo tres estrategias principales: \n",
    "- reemplazo por valores existentes,\n",
    "- reemplazo por valores estadísticos y,\n",
    "- reemplazo por valores predichos.\n",
    "\n",
    "Dependiendo de los valores usados para cada una de estas estrategias, usamos métodos que funcionan solo con valores numéricos y métodos que funcionan con columnas tanto numéricas como categóricas. Estos métodos se resumen en la siguiente Tabla  y se explican a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b4a97",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "| Reemplazo mediante:    | Sólo descriptores numéricos | Descriptores numéricos y categóricos |\n",
    "|---------------------------|--------------------------------------------------------------------------|--------------------------------|\n",
    "| Valores existentes   | Mínimo / Máximo                                                        | Anterior / Posterior / Fijo        |\n",
    "| Valores estadísticos | (Redondeado) Media / Mediana / Moving Average, Interpolación Lineal / Interpolación promedio | Más frecuente |\n",
    "|  Valores predichos   | Algoritmos de regresión                                                    | Algoritmos de regresión y clasificación, k-Nearest Neighbours |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71030d63",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "**Valor fijo**\n",
    "\n",
    "La imputación de valor fijo es un método general que funciona para todos los tipos de datos y consiste en sustituir el valor perdido por un valor fijo. Como ejemplo del uso de la imputación de valor fijo en descriptores categóricos, se puede imputar los valores perdidos en una encuesta con \"no respondido\".\n",
    "\n",
    "**Valor mínimo / máximo**\n",
    "\n",
    "Si se sabe que los datos deben ajustarse a un rango determinado [mínimo, máximo], y si sabe por el proceso de recopilación de datos que el sistema de medición deja de registrar y la señal se satura más allá de uno de esos límites, puede utilizar el rango mínimo o máximo como valor de reemplazo para los valores perdidos. Por ejemplo, si en el intercambio monetario se ha alcanzado un precio mínimo y el proceso de cambio se ha detenido, el precio de cambio monetario perdido puede reemplazarse con el valor mínimo de la frontera de cambio de la ley.\n",
    "\n",
    "**Media (redondeada) / Mediana / Media móvil**\n",
    "\n",
    "Otros métodos de imputación comunes para descriptores numéricos son: la media, la mediana o  la media móvil (moving average). En este caso, el método sustituye el valor perdido con la media o la mediana para todo el conjunto de datos. La media móvil se calcula en una ventana cercana al valor perdido, pero se suele usar más en series temporales.  En el caso de una gran cantidad de valores atípicos en su conjunto de datos, se recomienda utilizar la mediana en lugar de la media.\n",
    "\n",
    "**Valor más frecuente**\n",
    "\n",
    "Otro método común que funciona tanto para descriptores numéricos como categóricos, es usar el valor más frecuente en la columna para reemplazar los valores perdidos.\n",
    "\n",
    "**Valor anterior / siguiente**\n",
    "\n",
    "Existen métodos especiales de imputación para series de tiempo o datos ordenados. Estos métodos tienen en cuenta la naturaleza ordenada del conjunto de datos, donde los valores cercanos son probablemente más similares que los valores distantes. Un enfoque común para imputar valores perdidos en series de tiempo sustituye el valor anterior o siguiente por el valor perdido en la serie de tiempo. Este enfoque funciona tanto para valores numéricos como categóricos.\n",
    "\n",
    "**Interpolación lineal / promedio**\n",
    "\n",
    "De manera similar a la imputación de valor anterior / siguiente, pero solo aplicable a valores numéricos, es la interpolación lineal o promedio, que se calcula entre el valor disponible anterior y siguiente, y sustituye el valor perdido. Por supuesto, como para todas las operaciones con datos ordenados, es importante ordenar los datos correctamente por adelantado, por ejemplo, en el caso de datos de series de tiempo usando un *timestamp*.\n",
    "\n",
    "**K Nearest Neighbors**\n",
    "\n",
    "La idea aquí es buscar las K muestras más cercanas en el dataset, donde para el descriptor en cuestión, no se encuentre perdido su valor. Luego, se toma el valor del descriptor que ocurre con mayor frecuencia en dicha vecindad, como reemplazo del valor perdido.\n",
    "\n",
    "**Predicción del valor perdido**\n",
    "\n",
    "Otra opción común para la imputación única es entrenar un modelo de aprendizaje automático para predecir los valores de imputación para el descriptor $x$ en función de los otros descriptores. Las filas sin valores perdidos en el descriptor $x$ se utilizan como un conjunto de entrenamiento y el modelo se entrena en función de los valores de las otras columnas. Aquí podemos usar cualquier modelo de clasificación o regresión, dependiendo del tipo de datos del descriptor. Después del entrenamiento, el modelo se aplica a todas las muestras con valores perdidos del descriptor en cuestión, para predecir su valor más probable.\n",
    "\n",
    "En el caso de valores perdidos en más de una columna de descriptores, todos los valores perdidos se imputan primero temporalmente con un método de imputación básico, por ejemplo, el valor medio. A continuación, los valores de una sola columna vuelven a perderse. Posteriormente, el modelo se entrena y se aplica para completar esos valores perdidos. De esta manera, se entrena un modelo para cada descriptor con valores perdidos, hasta que todos los valores perdidos sean imputados por un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2270d42",
   "metadata": {},
   "source": [
    "#### Imputación Múltiple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6439cf5d",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "La imputación múltiple es un enfoque de imputación derivado de la estadística. Los métodos de imputación única tienen la desventaja de que no consideran la incertidumbre de los valores imputados. Esto significa que reconocen los valores imputados como valores reales sin tener en cuenta el error estándar, lo que provoca sesgos en los resultados.\n",
    "\n",
    "Un enfoque que resuelve este problema es la imputación múltiple donde no se crea una, sino muchas imputaciones para cada valor perdido. Esto significa completar los valores perdidos varias veces, creando múltiples conjuntos de datos “completos”.\n",
    "\n",
    "Se han desarrollado varios algoritmos para la imputación múltiple. Un algoritmo bien conocido es la [imputación múltiple por ecuación encadenada](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/) (MICE: Multiple Imputation by Chained Equation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaa7a16",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "**Imputación múltiple por ecuaciones encadenadas (MICE)**\n",
    "\n",
    "MICE es un método robusto e informativo para tratar los valores perdidos en los conjuntos de datos. MICE opera bajo el supuesto de que los datos faltantes son *Missing At Random*(MAR) o *Missing Complete At Random* (MCAR).\n",
    "\n",
    "El procedimiento es una extensión de la imputación simple por $\\text{predicción del valor perdido} (visto anteriormente): este es el paso 1. Sin embargo, hay dos pasos adicionales en el procedimiento de MICE.\n",
    "\n",
    "- Paso 1. Este proceso es el mismo que en en el procedimiento de imputación por $\\text{predicción del valor perdido} en un subconjunto de los datos originales. Un modelo se entrena para predecir los valores perdidos en un descriptor, utilizando los otros descriptores en la fila de datos como variables independientes para el modelo. Este paso se repite para todas los descriptores. Este paso es una iteración.\n",
    "\n",
    "- Paso 2: El paso 1 se repite $k$ veces, utilizando cada vez las imputaciones más recientes para las variables independientes, hasta que se alcanza la convergencia. La mayoría de las veces es suficiente con $k = 10$ iteraciones.\n",
    "\n",
    "- Paso 3: Todo el proceso se repite $N$ veces en $N$ subconjuntos aleatorios diferentes (¡similar a boostrap!). Los $N$ modelos resultantes serán ligeramente diferentes y producirán $N$ predicciones ligeramente diferentes para cada valor perdido.\n",
    "\n",
    "El análisis, por ejemplo, a través del entrenamiento de una regresión lineal para una variable objetivo, ahora se realiza en cada uno de los $N$ conjuntos de datos finales. Finalmente, los resultados se combinan, a esto se le suele llamar *pooling*.\n",
    "\n",
    "Este método proporciona resultados más sólidos que con una sola imputación. Por supuesto, la desventaja de tal robustez es el aumento de la complejidad computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5001a8b0",
   "metadata": {},
   "source": [
    "## Implementaciones del manejo de valores perdidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e2fd61b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T16:26:13.379886Z",
     "start_time": "2021-10-12T16:26:13.375495Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import mean, std, isnan, nan\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# To use this experimental feature, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475ff45f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:21:55.750811Z",
     "start_time": "2021-10-12T15:21:55.729819Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surgery</th>\n",
       "      <th>age</th>\n",
       "      <th>hospital_number</th>\n",
       "      <th>rectal_temp</th>\n",
       "      <th>pulse</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>temp_of_extremities</th>\n",
       "      <th>peripheral_pulse</th>\n",
       "      <th>mucous_membrane</th>\n",
       "      <th>capillary_refill_time</th>\n",
       "      <th>...</th>\n",
       "      <th>packed_cell_volume</th>\n",
       "      <th>total_protein</th>\n",
       "      <th>abdomo_appearance</th>\n",
       "      <th>abdomo_protein</th>\n",
       "      <th>outcome</th>\n",
       "      <th>surgical_lesion</th>\n",
       "      <th>lesion_1</th>\n",
       "      <th>lesion_2</th>\n",
       "      <th>lesion_3</th>\n",
       "      <th>cp_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>530101</td>\n",
       "      <td>38.5</td>\n",
       "      <td>66.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>11300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>534817</td>\n",
       "      <td>39.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>530334</td>\n",
       "      <td>38.3</td>\n",
       "      <td>40.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5290409</td>\n",
       "      <td>39.1</td>\n",
       "      <td>164.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>530255</td>\n",
       "      <td>37.3</td>\n",
       "      <td>104.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   surgery  age  hospital_number  rectal_temp  pulse  respiratory_rate  \\\n",
       "0      2.0    1           530101         38.5   66.0              28.0   \n",
       "1      1.0    1           534817         39.2   88.0              20.0   \n",
       "2      2.0    1           530334         38.3   40.0              24.0   \n",
       "3      1.0    9          5290409         39.1  164.0              84.0   \n",
       "4      2.0    1           530255         37.3  104.0              35.0   \n",
       "\n",
       "   temp_of_extremities  peripheral_pulse  mucous_membrane  \\\n",
       "0                  3.0               3.0              NaN   \n",
       "1                  NaN               NaN              4.0   \n",
       "2                  1.0               1.0              3.0   \n",
       "3                  4.0               1.0              6.0   \n",
       "4                  NaN               NaN              6.0   \n",
       "\n",
       "   capillary_refill_time  ...  packed_cell_volume  total_protein  \\\n",
       "0                    2.0  ...                45.0            8.4   \n",
       "1                    1.0  ...                50.0           85.0   \n",
       "2                    1.0  ...                33.0            6.7   \n",
       "3                    2.0  ...                48.0            7.2   \n",
       "4                    2.0  ...                74.0            7.4   \n",
       "\n",
       "   abdomo_appearance  abdomo_protein  outcome  surgical_lesion  lesion_1  \\\n",
       "0                NaN             NaN      2.0                2     11300   \n",
       "1                2.0             2.0      3.0                2      2208   \n",
       "2                NaN             NaN      1.0                2         0   \n",
       "3                3.0             5.3      2.0                1      2208   \n",
       "4                NaN             NaN      2.0                2      4300   \n",
       "\n",
       "   lesion_2  lesion_3  cp_data  \n",
       "0         0         0        2  \n",
       "1         0         0        2  \n",
       "2         0         0        1  \n",
       "3         0         0        1  \n",
       "4         0         0        2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/horse-colic.csv\", na_values=\"?\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d736d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:21:57.732080Z",
     "start_time": "2021-10-12T15:21:57.729092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e878288a",
   "metadata": {},
   "source": [
    "#### Eliminación de filas/columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d0b65",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "Luego podemos enumerar cada columna e informar el número de filas con valores perdidos para la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b154d238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "surgery                    1\n",
       "age                        0\n",
       "hospital_number            0\n",
       "rectal_temp               60\n",
       "pulse                     24\n",
       "respiratory_rate          58\n",
       "temp_of_extremities       56\n",
       "peripheral_pulse          69\n",
       "mucous_membrane           47\n",
       "capillary_refill_time     32\n",
       "pain                      55\n",
       "peristalsis               44\n",
       "abdominal_distention      56\n",
       "nasogastric_tube         104\n",
       "nasogastric_reflux       106\n",
       "nasogastric_reflux_ph    247\n",
       "rectal_exam_feces        102\n",
       "abdomen                  118\n",
       "packed_cell_volume        29\n",
       "total_protein             33\n",
       "abdomo_appearance        165\n",
       "abdomo_protein           198\n",
       "outcome                    1\n",
       "surgical_lesion            0\n",
       "lesion_1                   0\n",
       "lesion_2                   0\n",
       "lesion_3                   0\n",
       "cp_data                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e5bbdd",
   "metadata": {},
   "source": [
    "Podríamos eliminar todas las filas con valores perdidos usando `df.dropna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f10953c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:22:00.229328Z",
     "start_time": "2021-10-12T15:22:00.224083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df),len(df.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d387cc",
   "metadata": {},
   "source": [
    "Lo cual es absolutamente excesivo. \n",
    "\n",
    "Podríamos también eliminar las columnas con al menos un valor perdido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a0d7b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:22:02.933715Z",
     "start_time": "2021-10-12T15:22:02.928482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b13ff",
   "metadata": {},
   "source": [
    "Lo cual también es exagerado ya que pasamos de 28 columnas a 7.\n",
    "\n",
    "Podríamos intentar varias formas de disminuir esto, por ejemplo, eliminando columnas con alta nulidad, o mediante un umbral. Para esto, podríámos realizar un FOR o usar el parámetro `thresh` de `df.dropna()`. También, podríamos usar algún criterio para eliminar columnas, por ejemplo, eliminar columnas que tengan una varianza baja (usando `sklearn.feature_selection.VarianceThreshold`). O también, eliminar columnas con muy pocos valores, o que tengan muchos valores duplicados. En definitiva, pueden usar múltiples criterios de eliminación dependiendo de alguna condición."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852c1f2",
   "metadata": {},
   "source": [
    "Para las imputaciones que vienen a continuación es importante disponer de los datos X y la variable respuesta Y, en forma de array (no en dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd5cf015",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:24:41.647628Z",
     "start_time": "2021-10-12T15:24:41.626022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 1605\n"
     ]
    }
   ],
   "source": [
    "data = df.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "\n",
    "# imprime el total de perdidos\n",
    "print('Missing: %d' % sum(isnan(X).flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177087f8",
   "metadata": {},
   "source": [
    "#### Imputación única con `sklearn.impute.SimpleImputer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd000e",
   "metadata": {},
   "source": [
    "Seguramente han usado `df.fill()`, que es sencillo y fácil de ejecutar, pero tiene un problema muy grande: ¿cómo aplicamos exactamente la misma transformación a nuevos datos?. Es por esta razón, que es muy recomendable usar *transformers* de scikit-learn, tal y como se hace cuando se ejecuta una estandarización o se entrena un modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cfb395",
   "metadata": {},
   "source": [
    "Realicemos una estrategia de imputación única con la media y apliquemosla a los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e8bdd61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:22:43.958385Z",
     "start_time": "2021-10-12T15:22:43.954699Z"
    }
   },
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "Xtrans = imputer.fit_transform(X) # Ajusta y transforma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0816a54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:24:47.342827Z",
     "start_time": "2021-10-12T15:24:47.321462Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "# imprime el numero de valores perdidos\n",
    "print('Missing: %d' % sum(isnan(Xtrans).flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a117433",
   "metadata": {},
   "source": [
    "Es buena práctica evaluar la imputación (en este caso única) mediante la combinación con un modelo. Para esto, realizaremos un `Pipeline`, en donde el primer paso es la imputación y el segundo paso es el modelo. Posteriormente, haremos una validación cruzada (repetida) para evaluar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24dbe9cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:30:17.619264Z",
     "start_time": "2021-10-12T15:30:17.616449Z"
    }
   },
   "outputs": [],
   "source": [
    "# definiendo el pipeline\n",
    "model = RandomForestClassifier()\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "492d8477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T15:30:55.213969Z",
     "start_time": "2021-10-12T15:30:54.264423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.854 (0.051)\n"
     ]
    }
   ],
   "source": [
    "# definiendo la evaluacion del modelo\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluando el modelo\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a363d1a7",
   "metadata": {},
   "source": [
    "Ahora podemos comparar diferentes métodos de imputación para este mismo tipo de modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11fcaf16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T16:08:01.705344Z",
     "start_time": "2021-10-12T16:07:59.849918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">mean 0.854 (0.057)\n",
      ">median 0.868 (0.056)\n",
      ">most_frequent 0.872 (0.060)\n",
      ">constant 0.873 (0.050)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evalua cada estrategia en el dataset\n",
    "results = list()\n",
    "strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
    "for s in strategies:\n",
    "\t# crea el pipeline\n",
    "\tpipeline = Pipeline(steps=[('i', SimpleImputer(strategy=s)), ('m', RandomForestClassifier())])\n",
    "\t# evalua el modelo\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\t# almacena resultados\n",
    "\tresults.append(scores)\n",
    "\tprint('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
    "# grafica el desempeno del modelo para hacer una comparacion\n",
    "plt.boxplot(results, labels=strategies, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea2720f",
   "metadata": {},
   "source": [
    "Ahora veamos como se realiza una predicción con el mejor método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca2bf87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T16:13:14.281196Z",
     "start_time": "2021-10-12T16:13:14.195581Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 2\n"
     ]
    }
   ],
   "source": [
    "# crea el pipeline\n",
    "pipeline = Pipeline(steps=[('i', SimpleImputer(strategy='constant')), ('m', RandomForestClassifier())])\n",
    "# entrena el modelo \n",
    "pipeline.fit(X, y)\n",
    "# definimos un nuevo dato\n",
    "row = [2, 1, 530101, 38.50, 66, 28, 3, 3, nan, 2, 5, 4, 4, nan, nan, nan, 3, 5, 45.00, 8.40, nan, nan, 2, 11300, 00000, 00000, 2]\n",
    "# hacemos la prediccion\n",
    "yhat = pipeline.predict([row])\n",
    "# imprimimos la prediccion\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9344a9",
   "metadata": {},
   "source": [
    "#### Imputación (múltiple) con `sklearn.impute.IterativeImputer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0cbff",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "There are many well-established imputation packages in the R data science ecosystem: Amelia, mi, mice, missForest, etc. missForest is popular, and turns out to be a particular instance of different sequential imputation algorithms that can all be implemented with `IterativeImputer` by passing in different regressors to be used for predicting missing feature values. In the case of missForest, this regressor is a Random Forest. \n",
    "\n",
    "In the statistics community, it is common practice to perform multiple imputations, generating, for example, $m$ separate imputations for a single feature matrix. Each of these $m$ imputations is then put through the subsequent analysis pipeline (e.g. feature engineering, clustering, regression, classification). The m final analysis results (e.g. held-out validation errors) allow the data scientist to obtain understanding of how analytic results may differ as a consequence of the inherent uncertainty caused by the missing values. The above practice is called multiple imputation.\n",
    "\n",
    "Our implementation of `IterativeImputer` was inspired by the R MICE package (Multivariate Imputation by Chained Equations) 1, but differs from it by returning a single imputation instead of multiple imputations. However, `IterativeImputer` can also be used for multiple imputations by applying it repeatedly to the same dataset with different random seeds when `sample_posterior=True`. \n",
    "\n",
    "It is still an open problem as to how useful single vs. multiple imputation is in the context of prediction and classification when the user is not interested in measuring uncertainty due to missing values.\n",
    "\n",
    "---\n",
    "[Esto fue tomado de la documentación de scikit-learn](https://scikit-learn.org/stable/modules/impute.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8ae272",
   "metadata": {},
   "source": [
    "A continuación, realizaremos una imputación \"múltiple\" mediante regresión Bayesiana con regularización Ridge (`BayesianRidge()`). Usaremos el mismo procedimiento que se uso para la imputación única, esto es, construir un pipeline con un modelo de Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e755926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T16:32:24.460030Z",
     "start_time": "2021-10-12T16:32:23.575712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.870 (0.053)\n"
     ]
    }
   ],
   "source": [
    "# definiendo el modelo pipeline\n",
    "model = RandomForestClassifier()\n",
    "imputer = IterativeImputer()\n",
    "pipeline = Pipeline(steps=[('i', imputer), ('m', model)])\n",
    "# definiendo la evaluacion del modelo\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluando el modelo\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55652b4",
   "metadata": {},
   "source": [
    "Sin embargo, no sabemos si la estrategia iterativa por defecto en la mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f9446",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "De forma predeterminada, la imputación se realiza en orden ascendente desde la característica con menos valores perdidos hasta la característica con más. Esto tiene sentido, ya que queremos tener datos más completos cuando llega el momento de estimar los valores perdidos para las columnas donde faltan la mayoría de los valores.\n",
    "No obstante, podemos experimentar con diferentes estrategias de orden de imputación, descending, right-to-left (Arabic), left-to-right (Roman), y random.\n",
    "\n",
    "A continuación se evalúa y se compara cada configuración de orden de imputación disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d1194b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T16:49:38.945054Z",
     "start_time": "2021-10-12T16:49:36.196424Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">ascending 0.867 (0.054)\n",
      ">descending 0.869 (0.051)\n",
      ">roman 0.877 (0.054)\n",
      ">arabic 0.871 (0.058)\n",
      ">random 0.870 (0.054)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evalua cada estrategia sobre el dataset\n",
    "results = list()\n",
    "strategies = ['ascending', 'descending', 'roman', 'arabic', 'random']\n",
    "for s in strategies:\n",
    "\t# crea el pipeline\n",
    "\tpipeline = Pipeline(steps=[('i', IterativeImputer(imputation_order=s)), ('m', RandomForestClassifier())])\n",
    "\t# evalua el modelo\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\t# almacena resultados\n",
    "\tresults.append(scores)\n",
    "\tprint('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
    "# grafica la comparacion entre configuraciones\n",
    "plt.boxplot(results, labels=strategies, showmeans=True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be242c",
   "metadata": {
    "lang": "es"
   },
   "source": [
    "De forma predeterminada, `IterativeImputer` repetirá el número de iteraciones 10 veces.\n",
    "\n",
    "Es posible que una gran cantidad de iteraciones comience a sesgar la estimación y que se prefieran pocas iteraciones. El número de iteraciones del procedimiento se puede especificar mediante el argumento `max _iter`.\n",
    "\n",
    "Puede ser interesante evaluar diferentes números de iteraciones. A continuación, compararemos diferentes valores para \"max_ iter\" de 1 a 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38f553fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T16:56:02.674437Z",
     "start_time": "2021-10-12T16:55:53.296944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.867 (0.053)\n",
      ">2 0.870 (0.050)\n",
      ">3 0.868 (0.053)\n",
      ">4 0.871 (0.048)\n",
      ">5 0.872 (0.057)\n",
      ">6 0.872 (0.055)\n",
      ">7 0.876 (0.052)\n",
      ">8 0.864 (0.053)\n",
      ">9 0.871 (0.057)\n",
      ">10 0.873 (0.052)\n",
      ">11 0.874 (0.054)\n",
      ">12 0.874 (0.048)\n",
      ">13 0.869 (0.056)\n",
      ">14 0.860 (0.058)\n",
      ">15 0.872 (0.054)\n",
      ">16 0.873 (0.049)\n",
      ">17 0.873 (0.053)\n",
      ">18 0.871 (0.054)\n",
      ">19 0.872 (0.054)\n",
      ">20 0.872 (0.056)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evalua cada estrategia sobre el dataset\n",
    "results = list()\n",
    "strategies = [str(i) for i in range(1, 21)]\n",
    "for s in strategies:\n",
    "\t# pipeline\n",
    "\tpipeline = Pipeline(steps=[('i', IterativeImputer(max_iter=int(s))), ('m', RandomForestClassifier())])\n",
    "\t# evaluacion\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\t# resultados\n",
    "\tresults.append(scores)\n",
    "\tprint('>%s %.3f (%.3f)' % (s, mean(scores), std(scores)))\n",
    "# grafica de la comparacion\n",
    "plt.boxplot(results, labels=strategies, showmeans=True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790348f0",
   "metadata": {},
   "source": [
    "Realicemos ahora una predicción para un nuevo dato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4638b50f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T17:01:13.115971Z",
     "start_time": "2021-10-12T17:01:13.112799Z"
    }
   },
   "outputs": [],
   "source": [
    "row = [2, 1, 530101, 38.50, 66, 28, 3, 3, nan, 2, 5, 4, 4, nan, nan, nan, \\\n",
    "       3, 5, 45.00, 8.40, nan, nan, 2, 11300, 00000, 00000, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c62bd68b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-12T17:02:05.879985Z",
     "start_time": "2021-10-12T17:02:05.754885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 2\n"
     ]
    }
   ],
   "source": [
    "#  pipeline\n",
    "pipeline = Pipeline(steps=[('i', IterativeImputer()), ('m', RandomForestClassifier())])\n",
    "# entrenamiento \n",
    "pipeline.fit(X, y)\n",
    "# haciendo la prediccion\n",
    "yhat = pipeline.predict([row])\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a99486",
   "metadata": {},
   "source": [
    "### Otras formas de realizar imputación\n",
    "\n",
    "scikit-learn también implementa la imputación por vecino más cercanos al usar [`sklearn.impute.KNNImputer`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute).\n",
    "\n",
    "Otra librería que implementa más métodos de los vistos aquí es [faceimpute](https://github.com/iskandr/fancyimpute). La desventaja es que requiere a tensorflow (que es una librería grande)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacb99c0",
   "metadata": {},
   "source": [
    "# Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df921491",
   "metadata": {},
   "source": [
    "1. Repita la imputación realizada para el dataset `horse-colic.csv` usando `KNNImputer`, variando el número de vecinos. Pruebe con el nuevo dato.\n",
    "\n",
    "2. Repita el proceso de aplicar `IterativeImputer` pero esta vez usando `GridSearchCV` y variando una combinación entre la estrategia y el número de iteraciones máximo. Evalúe en el nuevo dato.\n",
    "\n",
    "3. En el dataset trabajado las variables categóricas ya han sido convertidas a enteros (además que se están realizando predicciones no enteras de los valores perdidos). Realice una imputación (única y/o múltiple)  sobre el dataset original `horse.csv` separando la estrategia de imputación dependiendo del tipo de variable. Al final, debe producir un dataframe con los datos imputados adecuadamente. Sugerencia: vea la primera y segunda respuesta de este [link](https://stackoverflow.com/questions/25239958/impute-categorical-missing-values-in-scikit-learn)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
